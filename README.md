ğŸ“š AI Backend â€“ RAG-based Study Assistant
A RAG-based AI backend built to power a smart study tool . It can answer doubts using domain-specific material and generate MCQs from uploaded PDFs using OpenAIâ€™s GPT models.

ğŸ§  Built with Retrieval-Augmented Generation (RAG) architecture
ğŸ” Uses Weaviate vector DB for semantic chunk search
ğŸ¤– Powered by OpenAI (gpt-3.5-turbo) for question answering and generation

âœ¨ Features
ğŸ“„ Upload Study Material
Upload PDFs and extract structured study chunks automatically.

ğŸ§  Vector-Based Retrieval
Chunks are stored in Weaviate for efficient topic or semantic search.

â“ Ask Doubts
Students can ask free-form questions, and the system retrieves relevant content and generates an LLM-based answer.

ğŸ“ Generate MCQs
Automatically generate 20 well-formatted MCQs for any topic using GPT and custom prompts.

ğŸ“Œ Topic-based Indexing
Each chunk is stored along with an auto-detected topic, enabling filtered search and quiz generation.

ğŸ§° Tech Stack

Layer	Tools Used
Backend    - Node.js, TypeScript, Express
AI/LLM     - OpenAI GPT-3.5 Turbo
Vector DB	 - Weaviate (Cloud Sandbox)
Parsing	   - pdf-parse
Database	 - Prisma (PostgreSQL, optional)
